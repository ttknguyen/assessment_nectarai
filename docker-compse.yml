version: '3.8'
services:
  vllm_model_1:
    image: vllm/vllm-openai:latest
    container_name: vllm_model_1
    runtime: nvidia
    environment:
      - HUGGING_FACE_HUB_TOKEN=abc_123
    ports:
      - "8001:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ipc: host
    command: >
      --model meta-llama/Llama-3.2-3B-Instruct
      --dtype=half
      --max-model-len=10000
      --gpu-memory-utilization=1

  vllm_model_2:
    image: vllm/vllm-openai:latest
    container_name: vllm_model_2
    runtime: nvidia
    environment:
      - HUGGING_FACE_HUB_TOKEN=abc_123
    ports:
      - "8002:8000"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    ipc: host
    command: >
      --model intfloat/e5-mistral-7b-instruct
      --dtype=half
      --max-model-len=10000
      --gpu-memory-utilization=1
